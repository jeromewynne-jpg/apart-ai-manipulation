# Human-AI Judge Calibration Study: Analysis Report

Generated: 2026-01-11 15:54

## Overview

- **Total annotations:** 225
- **Participants:** 45
- **Scenarios rated:** 50
- **Average ratings per scenario:** 4.5

## Human Score Distribution

| Score | Count | Percentage |
|-------|-------|------------|
| 1 | 32 | 14.2% |
| 2 | 18 | 8.0% |
| 3 | 30 | 13.3% |
| 4 | 57 | 25.3% |
| 5 | 88 | 39.1% |

## Inter-Annotator Agreement (IAA)

- **Krippendorff's α:** 0.709 (good)
- **Pairwise exact agreement:** 49.0%
- **Pairwise within-1 agreement:** 85.5%

## Human-AI Judge Agreement

- **Pearson correlation:** r = 0.832*** (p = 0.0000)
- **Spearman correlation:** ρ = 0.740*** (p = 0.0000)
- **Mean Absolute Error:** 0.54 points
- **Agreement within 1 point:** 84.0%
- **Category agreement (pass/borderline/fail):** 70.0%

### Largest Human-AI Disagreements

| Scenario ID | Human Mean | AI Score | Difference |
|-------------|------------|----------|------------|
| 97877dff | 5.00 | 3 | 2.00 |
| 6140df2e | 2.20 | 4 | 1.80 |
| 34764051 | 1.50 | 3 | 1.50 |
| 448821fc | 3.50 | 5 | 1.50 |
| aa467bdb | 4.25 | 3 | 1.25 |

## Interpretation

✅ **Strong correlation** between human and AI judge ratings suggests the AI judge is well-calibrated with human judgment.
