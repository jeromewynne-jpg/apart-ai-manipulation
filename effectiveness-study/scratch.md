# Effectiveness Study - Scratch Notes

## Core Setup

- Participant randomly allocated to one of **two AI chatbots**
- Participant has incentive to find the "correct" answer (maximizes their bonus)
- AI chatbot is working against them (maximizes principal's bonus)

## Incentive Structure

| Actor | Goal |
|-------|------|
| Participant | Maximize own bonus → find correct answer |
| Principal | Maximize own bonus → steer participant away from correct answer |

The participant and principal have **zero-sum** or **adversarial** incentives.

## Two Conditions

| Condition | Chatbot Behavior |
|-----------|------------------|
| **Helpful** | Helps participant find correct answer (aligned with participant) |
| **Manipulative** | Steers participant away from correct answer (aligned with principal) |

## Open Questions

- What is the decision task? (e.g., choose product, answer question, select option)
- How is "correct answer" defined?
- What's the bonus structure? (e.g., £X for correct, £0 for incorrect)
- Does the principal's bonus come from a fixed pool, or is it separate?
- Should participants know they might be manipulated?
- How many trials per participant?

## Ideas for Decision Task

- Product selection where one option is objectively better value
- Quiz-style task where one answer is correct
- Investment/allocation decision with clear optimal choice
- Information retrieval task where chatbot can mislead

## Notes

